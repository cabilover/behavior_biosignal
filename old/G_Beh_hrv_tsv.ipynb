{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006113e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy\n",
    "import fnmatch\n",
    "import pickle\n",
    "from deepdiff import DeepDiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c16500",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_beh_path = os.path.abspath(r'C:\\Users\\USER\\Guro_Psy_KJH Dropbox\\1.Projects\\1_anxiety_VR\\3_Data\\1_Behavior\\0_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e616a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: local location for raw behavior data from VRABES\n",
    "# Output: dictionary, key = sub-xxxx_ses-xx, value = list of path \n",
    "# reference: ref1 : 폴더명 생성 규칙 \n",
    "def gen_vrabes_paths (raw_beh_path): \n",
    "    dic_path = {}  \n",
    "    subs = os.listdir(raw_beh_path) \n",
    "    for sub in subs:\n",
    "        path2 = os.path.join(raw_beh_path,sub)\n",
    "        sess = os.listdir(path2) \n",
    "        for ses in sess:\n",
    "            path3 = os.path.join(path2,ses)\n",
    "            paths = os.listdir(path3) \n",
    "            dic_path['_'.join([sub,ses])] = paths           \n",
    "                \n",
    "    return dic_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21efe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: return from gen_vrabes_paths\n",
    "# output: dictionary, key = sub-xxxx_ses-xx, value = list of filename\n",
    "# reference: ref2 : Information and location by file\n",
    "\n",
    "def gen_vrabes_flist ():\n",
    "    a = gen_vrabes_paths(raw_beh_path)\n",
    "    dic_file = {}    \n",
    "    for key in a.keys():        \n",
    "        f_list=[]\n",
    "        for i in a[key]:\n",
    "            path_list = [raw_beh_path, key.split('_')[0], key.split('_')[1],i]      \n",
    "            p = os.path.join(*path_list)\n",
    "            f_list.extend(glob(p+'/*.csv'))\n",
    "            f_list.extend(glob(p+'/*.txt'))                      \n",
    "            \n",
    "        dic_file[key] = f_list\n",
    "    return dic_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53351a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고려 중 - 추후에 추가되는 실험 내용에 대하여 반영이 가능하게 고민 중\n",
    "def old_vrabes_ex():\n",
    "    with open('vrabes_beh_dict.pkl','rb') as f:\n",
    "        old_dict = pickle.load(f)\n",
    "    old_vrabes_dict = {}\n",
    "    for key in old_dict.keys():\n",
    "        col_list = old_dict[key].keys()\n",
    "        flist = []\n",
    "        for a in col_list:\n",
    "            col_names = a.split('_')[:-1]\n",
    "            fname = '_'.join(col_names)\n",
    "            if fname in flist:\n",
    "                pass\n",
    "            else: flist.append(fname)\n",
    "        old_vrabes_dict[key] = flist\n",
    "    return old_vrabes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b51186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고려 중- 추후에 추가되는 실험 내용에 대하여 반영이 가능하게 고민 중 - main 함수를 차이가 있는데서만 작동하도록\n",
    "# Input: pkl - generated dictionary from gen_df\n",
    "# Output: dictionary, Deepdiff -> ref4\n",
    "# Compares the dictionary generated by gen_dic_flist() of raw_beh_path at execution time \n",
    "# and the flist dictionary extracted from the existing storage dictionary from \"old_dict_ex\" \n",
    "# and returns the difference\n",
    "\n",
    "def diff_dic ():\n",
    "    new_dict = gen_vrabes_flist()\n",
    "    ex_new_dict = {}\n",
    "    for key in new_dict.keys():\n",
    "        new_flist =[]\n",
    "        for fname in new_dict[key]:\n",
    "            new_flist.append(fname.split('\\\\')[-1][:-4])\n",
    "        ex_new_dict[key] = new_flist\n",
    "\n",
    "    old_dict = old_vrabes_ex()\n",
    "    diff = DeepDiff(old_dict,ex_new_dict,verbose_level=2)\n",
    "    return diff\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c58f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: string from HRV_Result\n",
    "# output: string, name & val \n",
    "# reference: ref3 : Information and location by file\n",
    "def hrv_r_slicer (x):\n",
    "    eq_ind = x.find('=') \n",
    "    name = x[:eq_ind]\n",
    "    after_eq = x[eq_ind+1:] \n",
    "    if '(' in after_eq:\n",
    "        br_ind = after_eq.find('(')\n",
    "        val = x[eq_ind+2:eq_ind+br_ind+1] \n",
    "    else:\n",
    "        val = x[eq_ind+2:]\n",
    "    return name, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d9cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: generate pickle\n",
    "# output: dictionary, key = sub-xxxx_sex-xx, value = dataframe for each experiment\n",
    "\n",
    "def gen_vrabes_dict ():\n",
    "    f_path = gen_vrabes_flist()\n",
    "    result_dic = {}\n",
    "    for key in f_path.keys():\n",
    "        # print(key)        \n",
    "        dic_df = {}       \n",
    "        for i in f_path[key]:            \n",
    "            i_sp = i.split('\\\\')[-1]\n",
    "            if i_sp[-3:] == 'csv':\n",
    "                r_df = pd.read_csv(i,header=1)\n",
    "                col1 = i_sp[:-4]\n",
    "                if i_sp[-7:-4] =='HRV':\n",
    "                    col2 = r_df.columns[0]\n",
    "                    val = r_df.columns[1]\n",
    "                    dic_df['_'.join([col1,col2])] = val\n",
    "                else:\n",
    "                    for d in r_df.columns:\n",
    "                        val = r_df[d][0]\n",
    "                        dic_df['_'.join([col1,d])] = val  \n",
    "            elif i_sp[-3:] == 'txt':\n",
    "                r_df = pd.read_csv(i,header=None)\n",
    "                col1 = i_sp[:-4]\n",
    "                for e in r_df.loc[:,0]:\n",
    "                    col2, val = hrv_r_slicer(e)\n",
    "                    dic_df['_'.join([col1,col2])] = val\n",
    "        result_dic[key] = dic_df\n",
    "        result = pd.DataFrame(result_dic).transpose()\n",
    "        # result = result.transpose()\n",
    "    return result\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93060d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_crf_path = os.path.abspath(r'C:\\Users\\USER\\Guro_Psy_KJH Dropbox\\1.Projects\\1_anxiety_VR\\3_Data\\4_CRF')\n",
    "filename = ['VRABES_CRF_form.xlsx', 'VRABES_Demographic.xlsx']\n",
    "sheet = ['baseline','normal','anxiety','Demographic']\n",
    "drop = ['no','code','name']\n",
    "# header = 3, index_col = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da2eb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crf_pre (data):\n",
    "    data.drop(data.columns[data.columns.str.contains('Unnamed')],axis =1 , inplace = True)\n",
    "    data.drop([col for col in data.columns if any([x for x in drop if x == col])], axis=1, inplace=True)\n",
    "    data.dropna(subset = ['ID'], inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e14063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_total (raw_crf_path):\n",
    "    raw_df = gen_vrabes_dict ()\n",
    "    demo = pd.read_excel(os.path.join(raw_crf_path,'VRABES_Demographic.xlsx'), sheet_name= 'Demographic', header = 3, index_col= 'no')\n",
    "    ses_01_all = pd.read_excel(os.path.join(raw_crf_path,'VRABES_CRF_form.xlsx'), sheet_name= 'baseline', header = 3, index_col= 'no')\n",
    "    ses_02_nor = pd.read_excel(os.path.join(raw_crf_path,'VRABES_CRF_form.xlsx'), sheet_name= 'normal', header = 3, index_col= 'no')\n",
    "    anx = pd.read_excel(os.path.join(raw_crf_path,'VRABES_CRF_form.xlsx'), sheet_name= 'anxiety', header = 3, index_col= 'no')\n",
    "\n",
    "    demo = crf_pre(demo)\n",
    "    ses_01_all = crf_pre(ses_01_all)\n",
    "    ses_02_nor = crf_pre(ses_02_nor)\n",
    "    anx = crf_pre(anx)\n",
    "    ses_01_demo = demo.loc[:,list(dict.fromkeys(list(demo.columns)))]\n",
    "    ses_02_demo = demo.loc[:,list(dict.fromkeys(list(demo.columns)))]\n",
    "    ses_03_demo = demo.loc[:,list(dict.fromkeys(list(demo.columns)))]\n",
    "    ses_04_demo = demo.loc[:,list(dict.fromkeys(list(demo.columns)))]\n",
    "\n",
    "    i_ses02 = anx.columns.get_loc('visit_2_d')\n",
    "    i_ses03 = anx.columns.get_loc('visit_3_d')\n",
    "    i_ses04 = anx.columns.get_loc('visit_4_d')\n",
    "\n",
    "    ses_02_anx = pd.concat([anx.iloc[:,0],anx.iloc[:,1:i_ses03]], axis=1)\n",
    "    ses_03_anx = pd.concat([anx.iloc[:,0],anx.iloc[:,i_ses03:i_ses04]], axis=1)\n",
    "    ses_04_anx = pd.concat([anx.iloc[:,0],anx.iloc[:,i_ses04:]], axis=1)\n",
    "\n",
    "    ses_01_all.rename(columns = lambda x:'ses-01_' + x, inplace=True)\n",
    "    ses_01_demo.rename(columns = lambda x:'ses-01_' + x, inplace=True)\n",
    "    ses_02_nor.rename(columns = lambda x:'ses-02_' + x, inplace=True)\n",
    "    ses_02_anx.rename(columns = lambda x:'ses-02_' + x, inplace=True)\n",
    "    ses_02_demo.rename(columns = lambda x:'ses-02_' + x, inplace=True)\n",
    "    ses_03_anx.rename(columns = lambda x:'ses-03_' + x, inplace=True)\n",
    "    ses_03_demo.rename(columns = lambda x:'ses-03_' + x, inplace=True)\n",
    "    ses_04_anx.rename(columns = lambda x:'ses-04_' + x, inplace=True)\n",
    "    ses_04_demo.rename(columns = lambda x:'ses-04_' + x, inplace=True)\n",
    "\n",
    "    ses_01_all['ses-01_ID'] = ses_01_all.iloc[:,0].apply(lambda x:x+'_ses-01')\n",
    "    ses_01_demo['ses-01_ID'] = ses_01_demo.loc[:,'ses-01_ID'].apply(lambda x:x+'_ses-01')\n",
    "    ses_02_nor['ses-02_ID'] = ses_02_nor.iloc[:,0].apply(lambda x:x+'_ses-02')\n",
    "    ses_02_anx['ses-02_ID'] = ses_02_anx.iloc[:,0].apply(lambda x:x+'_ses-02')\n",
    "    ses_02_demo['ses-02_ID'] = ses_02_demo.loc[:,'ses-02_ID'].apply(lambda x:x+'_ses-02')\n",
    "    ses_03_anx['ses-03_ID'] = ses_03_anx.iloc[:,0].apply(lambda x:x+'_ses-03')\n",
    "    ses_03_demo['ses-03_ID'] = ses_03_demo.loc[:,'ses-03_ID'].apply(lambda x:x+'_ses-03')\n",
    "    ses_04_anx['ses-04_ID'] = ses_04_anx.iloc[:,0].apply(lambda x:x+'_ses-04')\n",
    "    ses_04_demo['ses-04_ID'] = ses_04_demo.loc[:,'ses-04_ID'].apply(lambda x:x+'_ses-04')\n",
    "\n",
    "    ses_01_all.rename(columns = {'ses-01_ID':'ID'}, inplace=True)\n",
    "    ses_01_demo.rename(columns = {'ses-01_ID':'ID'}, inplace=True)\n",
    "    ses_02_nor.rename(columns = {'ses-02_ID':'ID'}, inplace=True)\n",
    "    ses_02_anx.rename(columns = {'ses-02_ID':'ID'}, inplace=True)\n",
    "    ses_02_demo.rename(columns = {'ses-02_ID':'ID'}, inplace=True)\n",
    "    ses_03_anx.rename(columns = {'ses-03_ID':'ID'}, inplace=True)\n",
    "    ses_03_demo.rename(columns = {'ses-03_ID':'ID'}, inplace=True)\n",
    "    ses_04_anx.rename(columns = {'ses-04_ID':'ID'}, inplace=True)\n",
    "    ses_04_demo.rename(columns = {'ses-04_ID':'ID'}, inplace=True)\n",
    "\n",
    "    raw_df['ID'] = raw_df.index    \n",
    "    total = pd.merge(raw_df,ses_01_all, how='left', on ='ID')\n",
    "    total = pd.merge(total,ses_01_demo, how='left', on ='ID')\n",
    "    total = pd.merge(total,ses_02_nor, how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_02_anx,how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_02_demo,how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_03_anx,how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_03_demo,how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_04_anx,how='left', on ='ID')\n",
    "    total = pd.merge(total, ses_04_demo,how='left', on ='ID')\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd07289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_29424\\1287879585.py:5: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  ses_02_nor = pd.read_excel(os.path.join(raw_crf_path,'VRABES_CRF_form.xlsx'), sheet_name= 'normal', header = 3, index_col= 'no')\n"
     ]
    }
   ],
   "source": [
    "total = gen_total(raw_crf_path)\n",
    "with open('vrabes_beh_dict.pkl','wb') as f:\n",
    "    pickle.dump(total,f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90427409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      sub-0001_ses-01\n",
       "1      sub-0001_ses-02\n",
       "2      sub-0002_ses-01\n",
       "3      sub-0002_ses-02\n",
       "4      sub-0003_ses-01\n",
       "            ...       \n",
       "161    sub-0060_ses-03\n",
       "162    sub-0061_ses-01\n",
       "163    sub-0062_ses-01\n",
       "164    sub-0062_ses-02\n",
       "165    sub-0063_ses-01\n",
       "Name: ID, Length: 166, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total['ID']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "eeee73005f2d7c442ce01edc53b42ba7e639fc43199e10e3461fac3e3675672b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
